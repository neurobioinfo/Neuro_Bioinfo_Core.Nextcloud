{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Neuro_Bioinfo_Core Nextcloud Server Wiki! Neuro_Bioinfo_Core data storage platform As part of the NeuroVIP project, the Neuro Bioinfo Core group is offering a platform for all Neuro PIs who wish to store their data. This storage platform is intended for: * Long-term storage of large amounts of data, especially raw data * Files which are accessed only infrequently * MNI groups with storage needs greater than the default offered by the DRAC, but who do not wish to write yearly computing grants to secure it. * MNI groups who would prefer a more intuitive graphical way to manage their raw data, backed by experienced in-house informatics support. * All types of data, excluding the fundamental MRI/PET imaging that is routinely stored on the Neuro BIC server Front end: Nextcloud server We have mounted a Nextcloud server as the portal for Neuro PIs to manage their data. Nextcloud is an open-source data sharing platform similar to Dropbox. Click here to access the Neuro_Bioinfo_Core Nextcloud server See the official Nextcloud documentation for general instructions on how to use the Nextcloud web interface. Note: we have not implemented all features from the above link. For example, we do not support using Nextcloud as an email client, nor do we support multi-factor authentication at this time. Back end: DRAC cloud infrastructure Behind the scenes, the Nextcloud server provides a bridge to a large cloud storage resource allocated to the Neuro Bioinfo Core by the Digital Research Alliance of Canada (DRAC). This cloud storage, very similar in structure to Amazon's Simple Storage Service (AWS S3), is managed and operated entirely by the Neuro Bioinfo Core. The Nextcloud front-end server provides the access control necessary for multiple groups to manage their data in this common space, without risking unwanted access between groups. Questions or comments Please direct any questions, comments or general support requests to neurobioinfo@mcgill.ca Contents Getting Started Upload data Redundant Backups Best Practices for Data Storage Download data","title":"Home"},{"location":"#welcome-to-the-neuro_bioinfo_core-nextcloud-server-wiki","text":"","title":"Welcome to the Neuro_Bioinfo_Core Nextcloud Server Wiki!"},{"location":"#neuro_bioinfo_core-data-storage-platform","text":"As part of the NeuroVIP project, the Neuro Bioinfo Core group is offering a platform for all Neuro PIs who wish to store their data. This storage platform is intended for: * Long-term storage of large amounts of data, especially raw data * Files which are accessed only infrequently * MNI groups with storage needs greater than the default offered by the DRAC, but who do not wish to write yearly computing grants to secure it. * MNI groups who would prefer a more intuitive graphical way to manage their raw data, backed by experienced in-house informatics support. * All types of data, excluding the fundamental MRI/PET imaging that is routinely stored on the Neuro BIC server","title":"Neuro_Bioinfo_Core data storage platform"},{"location":"#front-end-nextcloud-server","text":"We have mounted a Nextcloud server as the portal for Neuro PIs to manage their data. Nextcloud is an open-source data sharing platform similar to Dropbox. Click here to access the Neuro_Bioinfo_Core Nextcloud server See the official Nextcloud documentation for general instructions on how to use the Nextcloud web interface. Note: we have not implemented all features from the above link. For example, we do not support using Nextcloud as an email client, nor do we support multi-factor authentication at this time.","title":"Front end: Nextcloud server"},{"location":"#back-end-drac-cloud-infrastructure","text":"Behind the scenes, the Nextcloud server provides a bridge to a large cloud storage resource allocated to the Neuro Bioinfo Core by the Digital Research Alliance of Canada (DRAC). This cloud storage, very similar in structure to Amazon's Simple Storage Service (AWS S3), is managed and operated entirely by the Neuro Bioinfo Core. The Nextcloud front-end server provides the access control necessary for multiple groups to manage their data in this common space, without risking unwanted access between groups.","title":"Back end: DRAC cloud infrastructure"},{"location":"#questions-or-comments","text":"Please direct any questions, comments or general support requests to neurobioinfo@mcgill.ca","title":"Questions or comments"},{"location":"#contents","text":"Getting Started Upload data Redundant Backups Best Practices for Data Storage Download data","title":"Contents"},{"location":"bpds/","text":"Primary Data: Raw These should be exclusively the primary \"big data\" generated by sequencers, genotypers, light-sheet, EM etc. In other words, this data cannot be regenerated without repeating the initial experiment. This - and ONLY this data - will be backed up in duplicate copies following our backup policy . NOTE: this platform is not intended to support the very large amounts of fundamental imaging (human MRI/PET) that Neuro PIs currently store on the BIC server. If you wish this data to be backed up, its parent directory must be named \"raw.data\" (lowercase), found within your group's main data folder, i.e. the one named [PIname]Lab, with a folder-and-arrow icon ( ). Within this \"raw.data\" folder, your data may have any structure you like. However it is good practice to have directory structures that are as informative as possible. For example this might include: * Having sub-folders by data type, e.g. genotyping, dnaseq, bulk Rnaseq, single-cell RNAseq, ATAC-seq, light-sheet, EM, microscopy etc. * Having sub-folders by project name Common raw data file types include: fastq/bam/cram (for sequence data), jpg/idat/txt (for genotyping data) Secondary and Tertiary Data: Analyzed These are the data generated from computationally-intensive analyses of your primary data. Users should apply discretion when deciding whether or not to store non-primary data on the Neuro_Bioinfo_Core storage platform. Reasons to store non-primary data include: It is the product of very large amounts of computation and would be very costly/time-consuming to replace. (e.g. joint-called vcf for a large cohort) It is a valuable project deliverable in itself It is a common input for many downstream analyses (e.g. RNAseq gene count matrices) You are required to keep it by university policy/publication requirement/grant mandate etc. We strongly discourage users from simply stockpiling all the files generated by their analyses with no curation. Practices to avoid include: * Preserving intermediary files, i.e. those used only to generate final outputs. e.g.: * Alignment bam files produced by post-processing steps in dnaseq/rnaseq analyses * Single-sample dnaseq variant vcf files * Genotype files in various stages of filtration * Preserving files which are easy/quick/inexpensive to regenerate * Preserving extremely verbose analysis logs, core dumps, or files of unknown use/provenance Personal or Non-Data files Should ideally be stored outside of your group's main data folder, i.e. not in the one named [PIname]Lab, with a folder-and-arrow icon ( ). You can create any number of private folders in Nextcloud. You can name and organize them any way you like. Common Considerations Data compression should be used whenever possible to save space. In particular, large plain-text formats such as fastq should be compressed with a utility like gzip. Large collections of small files should be packaged whenever possible into archive formats such as tar/dar or zip. Data stored on this platform are not intended to be accessed frequently. Consider using a resource like the Digital Research Alliance of Canada (DRAC) server /project space for files that your group will re-use often. Sharing files with external users via this platform is possible, but not optimal for large datasets. If you wish to share large amounts of data to a user outside this platform, please contact neurobioinfo@mcgill.ca for assistance. Additional Resources Digital Research Alliance of Canada - Data Management Best Practices Digital Research Alliance of Canada - Building Documentation and Metadata","title":"Best Practices for Data Storage"},{"location":"bpds/#primary-data-raw","text":"These should be exclusively the primary \"big data\" generated by sequencers, genotypers, light-sheet, EM etc. In other words, this data cannot be regenerated without repeating the initial experiment. This - and ONLY this data - will be backed up in duplicate copies following our backup policy . NOTE: this platform is not intended to support the very large amounts of fundamental imaging (human MRI/PET) that Neuro PIs currently store on the BIC server. If you wish this data to be backed up, its parent directory must be named \"raw.data\" (lowercase), found within your group's main data folder, i.e. the one named [PIname]Lab, with a folder-and-arrow icon ( ). Within this \"raw.data\" folder, your data may have any structure you like. However it is good practice to have directory structures that are as informative as possible. For example this might include: * Having sub-folders by data type, e.g. genotyping, dnaseq, bulk Rnaseq, single-cell RNAseq, ATAC-seq, light-sheet, EM, microscopy etc. * Having sub-folders by project name Common raw data file types include: fastq/bam/cram (for sequence data), jpg/idat/txt (for genotyping data)","title":"Primary Data: Raw"},{"location":"bpds/#secondary-and-tertiary-data-analyzed","text":"These are the data generated from computationally-intensive analyses of your primary data. Users should apply discretion when deciding whether or not to store non-primary data on the Neuro_Bioinfo_Core storage platform. Reasons to store non-primary data include: It is the product of very large amounts of computation and would be very costly/time-consuming to replace. (e.g. joint-called vcf for a large cohort) It is a valuable project deliverable in itself It is a common input for many downstream analyses (e.g. RNAseq gene count matrices) You are required to keep it by university policy/publication requirement/grant mandate etc. We strongly discourage users from simply stockpiling all the files generated by their analyses with no curation. Practices to avoid include: * Preserving intermediary files, i.e. those used only to generate final outputs. e.g.: * Alignment bam files produced by post-processing steps in dnaseq/rnaseq analyses * Single-sample dnaseq variant vcf files * Genotype files in various stages of filtration * Preserving files which are easy/quick/inexpensive to regenerate * Preserving extremely verbose analysis logs, core dumps, or files of unknown use/provenance","title":"Secondary and Tertiary Data: Analyzed"},{"location":"bpds/#personal-or-non-data-files","text":"Should ideally be stored outside of your group's main data folder, i.e. not in the one named [PIname]Lab, with a folder-and-arrow icon ( ). You can create any number of private folders in Nextcloud. You can name and organize them any way you like.","title":"Personal or Non-Data files"},{"location":"bpds/#common-considerations","text":"Data compression should be used whenever possible to save space. In particular, large plain-text formats such as fastq should be compressed with a utility like gzip. Large collections of small files should be packaged whenever possible into archive formats such as tar/dar or zip. Data stored on this platform are not intended to be accessed frequently. Consider using a resource like the Digital Research Alliance of Canada (DRAC) server /project space for files that your group will re-use often. Sharing files with external users via this platform is possible, but not optimal for large datasets. If you wish to share large amounts of data to a user outside this platform, please contact neurobioinfo@mcgill.ca for assistance.","title":"Common Considerations"},{"location":"bpds/#additional-resources","text":"Digital Research Alliance of Canada - Data Management Best Practices Digital Research Alliance of Canada - Building Documentation and Metadata","title":"Additional Resources"},{"location":"download_data/","text":"Downloading large datasets To download a large dataset from our cloud you need to have installed the package \"rclone\". If you're downloading on DRAC clusters, rclone is already installed. Next steps will guide you in the downloading process using a command line: 1. If you're not downloading in DRAC clusters, install rclone: sudo apt install rclone 2. Setup rclone configuration (you will need your NeuroVIP user name and your password) Run next command to setup rclone configuration. Make this whether you have a local installation of rclone, or if you are going to download on DRAC clusters. rclone config Chose or type next options for the different parameters: Chose \"n\" #for new remote Enter name for new remote --> neurovip Type of storage to configure --> <number> / WebDAV URL of http host to connect to --> https://206-12-88-239.cloud.computecanada.ca/nextcloud/remote.php/dav/files/<your NeuroVIP username> Name of the WebDAV site/service/software you are using --> <number> / Nextcloud User name --> <your NeuroVIP username> chose \"y\" to enter password Password --> <your password> Leave \"Option bearer_token\" empty choose \"no\" for \"Edit advanced config\" choose \"yes\" for \"Keep this 'nextcloud' remote\" choose \"q\" to quit config 3. Go to your download folder and create a folder that will receive the data: cd <download folder> mkdir <destination folder name> 4. Run next comant to begin downloading rclone sync -v neurovip:/path/file <destination folder name> 2>&1|tee -a nexcloud_download.log Notes: If downloading gets interrupted the same command will resume the download. The log file contains all information about the download. If you're on a Compute Canada server, you may want run this command within an \"screen\" created with the \"screen\" command.","title":"Downloading large datasets"},{"location":"download_data/#downloading-large-datasets","text":"To download a large dataset from our cloud you need to have installed the package \"rclone\". If you're downloading on DRAC clusters, rclone is already installed. Next steps will guide you in the downloading process using a command line:","title":"Downloading large datasets"},{"location":"download_data/#1-if-youre-not-downloading-in-drac-clusters-install-rclone","text":"sudo apt install rclone","title":"1. If you're not downloading in DRAC clusters, install rclone:"},{"location":"download_data/#2-setup-rclone-configuration-you-will-need-your-neurovip-user-name-and-your-password","text":"Run next command to setup rclone configuration. Make this whether you have a local installation of rclone, or if you are going to download on DRAC clusters. rclone config Chose or type next options for the different parameters: Chose \"n\" #for new remote Enter name for new remote --> neurovip Type of storage to configure --> <number> / WebDAV URL of http host to connect to --> https://206-12-88-239.cloud.computecanada.ca/nextcloud/remote.php/dav/files/<your NeuroVIP username> Name of the WebDAV site/service/software you are using --> <number> / Nextcloud User name --> <your NeuroVIP username> chose \"y\" to enter password Password --> <your password> Leave \"Option bearer_token\" empty choose \"no\" for \"Edit advanced config\" choose \"yes\" for \"Keep this 'nextcloud' remote\" choose \"q\" to quit config","title":"2. Setup rclone configuration (you will need your NeuroVIP user name and your password)"},{"location":"download_data/#3-go-to-your-download-folder-and-create-a-folder-that-will-receive-the-data","text":"cd <download folder> mkdir <destination folder name>","title":"3. Go to your download folder and create a folder that will receive the data:"},{"location":"download_data/#4-run-next-comant-to-begin-downloading","text":"rclone sync -v neurovip:/path/file <destination folder name> 2>&1|tee -a nexcloud_download.log","title":"4. Run next comant to begin downloading"},{"location":"download_data/#notes","text":"If downloading gets interrupted the same command will resume the download. The log file contains all information about the download. If you're on a Compute Canada server, you may want run this command within an \"screen\" created with the \"screen\" command.","title":"Notes:"},{"location":"getting_started/","text":"Getting Started on the Neuro_Bioinfo_Core Nextcloud Server New groups If you are a PI and wish to begin storing your data on the Neuro_Bioinfo_Core storage platform, please follow these steps: 1. Contact neurobioinfo@mcgill.ca and let us know. An admin will create your group and all necessary folders on the nextcloud server. 2. You will be notified as soon as your group has been created, and given the initial username and password for your group admin user. You can change this password after your first login 3. Optionally, we can create any number of additional users when we create your group. For each additional user you will need to provide us: The user's full name The user's email address * Whether any storage quotas should be applied to this user (default: no) * Whether or not the user should have group admin privileges (default: no) Alternately, you can create your own users following the instructions below. New users By default the first user created for a new group will be the group admin. This should be the group PI, though of course PIs are at their discretion to delegate this job behind the scenes to another member of their lab. Group admins can easily create new users for their groups on Nextcloud via the following steps: 1. Click on your user icon in the top-right of the screen and select \"Users\" from the drop-menu 2. Click the \"New User\" button on the left side pannel 3. Fill in the form that pops up with the relevant info. * Be sure to add the user to your group! * You will have to set an initial password for new users. The user can later change the password to one of their choosing Creating additional Nextcloud Groups under the same PI By default, PIs will be assigned only a single nextcloud group. Only system admins can create new groups. If you would like to create another, please contact neurobioinfo@mcgill.ca to discuss your needs. Next steps You are now ready to start uploading your data . Be sure to see our suggestions for storage best practises , as well as consulting our data backup policy .","title":"Getting Started"},{"location":"getting_started/#getting-started-on-the-neuro_bioinfo_core-nextcloud-server","text":"","title":"Getting Started on the Neuro_Bioinfo_Core Nextcloud Server"},{"location":"getting_started/#new-groups","text":"If you are a PI and wish to begin storing your data on the Neuro_Bioinfo_Core storage platform, please follow these steps: 1. Contact neurobioinfo@mcgill.ca and let us know. An admin will create your group and all necessary folders on the nextcloud server. 2. You will be notified as soon as your group has been created, and given the initial username and password for your group admin user. You can change this password after your first login 3. Optionally, we can create any number of additional users when we create your group. For each additional user you will need to provide us: The user's full name The user's email address * Whether any storage quotas should be applied to this user (default: no) * Whether or not the user should have group admin privileges (default: no) Alternately, you can create your own users following the instructions below.","title":"New groups"},{"location":"getting_started/#new-users","text":"By default the first user created for a new group will be the group admin. This should be the group PI, though of course PIs are at their discretion to delegate this job behind the scenes to another member of their lab. Group admins can easily create new users for their groups on Nextcloud via the following steps: 1. Click on your user icon in the top-right of the screen and select \"Users\" from the drop-menu 2. Click the \"New User\" button on the left side pannel 3. Fill in the form that pops up with the relevant info. * Be sure to add the user to your group! * You will have to set an initial password for new users. The user can later change the password to one of their choosing","title":"New users"},{"location":"getting_started/#creating-additional-nextcloud-groups-under-the-same-pi","text":"By default, PIs will be assigned only a single nextcloud group. Only system admins can create new groups. If you would like to create another, please contact neurobioinfo@mcgill.ca to discuss your needs.","title":"Creating additional Nextcloud Groups under the same PI"},{"location":"getting_started/#next-steps","text":"You are now ready to start uploading your data . Be sure to see our suggestions for storage best practises , as well as consulting our data backup policy .","title":"Next steps"},{"location":"redundant_backups/","text":"Purpose/Principle Best practice for archiving of essential data is that it should exist in multiple independent copies. This is meant to serve as a hedge against accidental deletion (human error) or equipment failure. The Neuro_Bioinfo_Core storage platform applies this principle to key data for each participating research group. Requirements and Limitations This backup policy is intended to be applied to raw data only. Any files which can be re-generated are not meant to be included. Data to be backed up must be contained within your group's main folder, i.e. the one named [PIname]Lab, with a folder-and-arrow icon ( ) Within that parent folder, data to be backed up will be the entire contents of the sub-folder named \"raw.data\". Only data in this folder will be backed up Users are on their honour to put only essential raw data in this folder. We may occasionally audit the space to ensure this practise is being respected Please consult our best practices for data storage How it Works On scheduled intervals, server admins will create a second copy of all data contained in each group's [PIname]/raw.data folder. This copy will reside in a separate s3 bucket owned by the Neuro_Bioinfo_Core storage project. It will be accessible only to Neuro Bioinfo Core staff. Restoring Accidentally Deleted Data First, always look in your nextcloud trash folder; smaller and/or just-deleted files will often be retained there and can be restored without administrator action If you cannot restore the data yourself from the trash, please send a message to neurobioinfo@mcgill.ca that includes the full directory path(s) of the data to be restored, whenever possible Disclaimer This backup policy will be in place until we approach the ultimate limits of our storage capacity (350TB for 2023, 400TB for 2024, 500TB for 2025). Should we ever reach the point where ongoing backups will hamper our ability to host new data, this backup policy may be changed.","title":"Redundant Backups"},{"location":"redundant_backups/#purposeprinciple","text":"Best practice for archiving of essential data is that it should exist in multiple independent copies. This is meant to serve as a hedge against accidental deletion (human error) or equipment failure. The Neuro_Bioinfo_Core storage platform applies this principle to key data for each participating research group.","title":"Purpose/Principle"},{"location":"redundant_backups/#requirements-and-limitations","text":"","title":"Requirements and Limitations"},{"location":"redundant_backups/#this-backup-policy-is-intended-to-be-applied-to-raw-data-only","text":"Any files which can be re-generated are not meant to be included. Data to be backed up must be contained within your group's main folder, i.e. the one named [PIname]Lab, with a folder-and-arrow icon ( ) Within that parent folder, data to be backed up will be the entire contents of the sub-folder named \"raw.data\". Only data in this folder will be backed up Users are on their honour to put only essential raw data in this folder. We may occasionally audit the space to ensure this practise is being respected Please consult our best practices for data storage","title":"This backup policy is intended to be applied to raw data only."},{"location":"redundant_backups/#how-it-works","text":"On scheduled intervals, server admins will create a second copy of all data contained in each group's [PIname]/raw.data folder. This copy will reside in a separate s3 bucket owned by the Neuro_Bioinfo_Core storage project. It will be accessible only to Neuro Bioinfo Core staff.","title":"How it Works"},{"location":"redundant_backups/#restoring-accidentally-deleted-data","text":"First, always look in your nextcloud trash folder; smaller and/or just-deleted files will often be retained there and can be restored without administrator action If you cannot restore the data yourself from the trash, please send a message to neurobioinfo@mcgill.ca that includes the full directory path(s) of the data to be restored, whenever possible","title":"Restoring Accidentally Deleted Data"},{"location":"redundant_backups/#disclaimer","text":"This backup policy will be in place until we approach the ultimate limits of our storage capacity (350TB for 2023, 400TB for 2024, 500TB for 2025). Should we ever reach the point where ongoing backups will hamper our ability to host new data, this backup policy may be changed.","title":"Disclaimer"},{"location":"upload_data/","text":"Moving Data onto Neuro_Bioinfo_Core Nextcloud Server From your local machine This option is most appropriate for smaller datasets, usually hosted on your local machine or an external drive Log into the Neuro_Bioinfo_Core Nextcloud server and click the \"Files\" icon on the top-left Navigate to your group's data folder (hint: name most likely will be \"[PI's last name]Lab\") Click on the \"+\" button and choose \"Upload file\" Create local folders as needed to organize your data From Digital Alliance HPC: This option is most appropriate for larger datasets, in particular those which are already stored on some HPC server hosted by the Digital Alliance Copy data to your group's sub-folder within /lustre04/scratch/spiegelm/Neuro_Bioinfo_Core.Nextcloud/transfer_tmp on beluga.computecanada.ca Connect to beluga by your preferred method (filezilla, globus, terminal command-line, etc.) If a folder for your group doesn't already exist, please ask the Neuro Bioinfo Core to create it for you you MUST set your linux permissions so the \"other\" user can read all files, and read + execute all folders you wish to upload. i.e. in your upload folder, run the following commands: find -type f -exec chmod o+r {} \\; find -type d -exec chmod o+rx {} \\; don't worry, once they are on nextcloud, these permissions will no longer apply; it's just to manage the upload Wait at least 6 hours before going to the next step. The data has to migrate behind the scenes If you want to move in more than 5TB of data at a time, please contact neurobioinfo@mcgill.ca to co-ordinate before you begin Log into the Neuro_Bioinfo_Core Nextcloud server and click the \"Files\" icon on the top-left Navigate to your group's data folder (name will be something like \"[PI's last name]Lab\") If the transfer has completed successfully, all the folders you copied in step 1 should be there. If your data does not appear where it should - Try again in a few hours (especially if there is a large data transfer underway) - Contact the NeuroBioinfo Core at neurobioinfo@mcgill.ca for support","title":"Upload data"},{"location":"upload_data/#moving-data-onto-neuro_bioinfo_core-nextcloud-server","text":"","title":"Moving Data onto Neuro_Bioinfo_Core Nextcloud Server"},{"location":"upload_data/#from-your-local-machine","text":"This option is most appropriate for smaller datasets, usually hosted on your local machine or an external drive Log into the Neuro_Bioinfo_Core Nextcloud server and click the \"Files\" icon on the top-left Navigate to your group's data folder (hint: name most likely will be \"[PI's last name]Lab\") Click on the \"+\" button and choose \"Upload file\" Create local folders as needed to organize your data","title":"From your local machine"},{"location":"upload_data/#from-digital-alliance-hpc","text":"This option is most appropriate for larger datasets, in particular those which are already stored on some HPC server hosted by the Digital Alliance Copy data to your group's sub-folder within /lustre04/scratch/spiegelm/Neuro_Bioinfo_Core.Nextcloud/transfer_tmp on beluga.computecanada.ca Connect to beluga by your preferred method (filezilla, globus, terminal command-line, etc.) If a folder for your group doesn't already exist, please ask the Neuro Bioinfo Core to create it for you you MUST set your linux permissions so the \"other\" user can read all files, and read + execute all folders you wish to upload. i.e. in your upload folder, run the following commands: find -type f -exec chmod o+r {} \\; find -type d -exec chmod o+rx {} \\; don't worry, once they are on nextcloud, these permissions will no longer apply; it's just to manage the upload Wait at least 6 hours before going to the next step. The data has to migrate behind the scenes If you want to move in more than 5TB of data at a time, please contact neurobioinfo@mcgill.ca to co-ordinate before you begin Log into the Neuro_Bioinfo_Core Nextcloud server and click the \"Files\" icon on the top-left Navigate to your group's data folder (name will be something like \"[PI's last name]Lab\") If the transfer has completed successfully, all the folders you copied in step 1 should be there. If your data does not appear where it should - Try again in a few hours (especially if there is a large data transfer underway) - Contact the NeuroBioinfo Core at neurobioinfo@mcgill.ca for support","title":"From Digital Alliance HPC:"},{"location":"upload_data/#_1","text":"","title":""}]}